use crate::parser;

#[derive(Debug, PartialEq, Eq, Clone, Hash)]
pub enum TokenKinds {
    /// A sequence of characters
    Token(String),
    /// A string of characters that will be generated by the preprocessor
    Complex(String),
    Text,
    Whitespace,
    Control(ControlTokenKind),
}

#[derive(Debug, PartialEq, Eq, Clone, Hash)]
pub enum ControlTokenKind {
    Eof,
    Eol,
}

pub struct Lexer<'a> {
    /// Reference to the text being lexed
    pub(crate) text: &'a str,
    /// Possible token kinds
    token_kinds: Vec<String>,
    /// Tokens that have been lexed
    pub tokens: Vec<Token>,
}

#[derive(Debug, PartialEq, Eq, Clone, Hash)]
pub struct Token {
    /// Index of the token in the text
    pub index: usize,
    /// Length of the token
    pub len: usize,
    /// Location for debugging
    pub location: TextLocation,
    /// Kind of token
    pub kind: TokenKinds,
}

#[derive(Debug, PartialEq, Eq, Clone, Hash)]
pub struct TextLocation {
    pub line: usize,
    pub column: usize,
}

impl<'a> Lexer<'a> {
    pub fn new(text: &'a str) -> Lexer<'a> {
        Lexer {
            text,
            token_kinds: Vec::new(),
            tokens: Vec::new(),
        }
    }

    pub fn add_tokens(&mut self, tokens: &[String]) {
        self.token_kinds.reserve(tokens.len());
        for token in tokens {
            self.token_kinds.push(token.clone());
        }
    }

    pub fn add_token(&mut self, token: String) {
        self.token_kinds.push(token);
    }

    pub fn lex(&mut self) -> Vec<Token> {
        let chars = self.text.chars().collect::<Vec<char>>();
        let mut tokens = Vec::new();
        let mut i = 0;
        let mut line = 0;
        let mut column = 0;
        'chars: while i < chars.len() {
            // Take new line into account
            if chars[i] == '\n' {
                line += 1;
                column = 0;
                i += 1;
                tokens.push(Token {
                    index: i,
                    len: 1,
                    location: TextLocation {
                        line: line,
                        column: column,
                    },
                    kind: TokenKinds::Control(ControlTokenKind::Eol),
                });
                continue;
            }

            // Match token kinds
            for token_kind in &self.token_kinds {
                let mut token;
                let mut j = 0;
                while i + j < chars.len() {
                    token = &self.text[i..i + j + 1];
                    if token == *token_kind {
                        tokens.push(Token {
                            index: i,
                            len: j + 1,
                            location: TextLocation {
                                line,
                                column,
                            },
                            kind: TokenKinds::Token(token.to_string()),
                        });
                        i += j + 1;
                        column += j + 1;
                        continue 'chars;
                    }
                    j += 1;
                }
            }

            // Match whitespace
            if chars[i].is_whitespace() {
                tokens.push(Token {
                    index: i,
                    len: 1,
                    location: TextLocation { line, column },
                    kind: TokenKinds::Whitespace,
                });
                i += 1;
                column += 1;
                continue;
            }

            // Match text until next whitespace/token/eof
            let mut j = 0;
            'word: while i + j < chars.len() {
                if chars[i + j].is_whitespace() {
                    break;
                }
                for token_kind in &self.token_kinds {
                    // FIXME: A loooooot of unnecessary allocations
                    if chars[i + j..].starts_with(&token_kind.chars().collect::<Vec<char>>()) {
                        break 'word;
                    }
                }
                j += 1;
            }
            tokens.push(Token {
                index: i,
                len: j,
                location: TextLocation { line, column },
                kind: TokenKinds::Text,
            });
            column += j;
            i += j;
        }
        tokens.push(Token {
            index: i,
            len: 0,
            location: TextLocation { line, column },
            kind: TokenKinds::Control(ControlTokenKind::Eof),
        });
        tokens
    }

    /// Takes a slice of tokens and returns a string of the text
    pub fn stringify_slice(&self, tokens: &[Token]) -> String {
        let start = match tokens.first() {
            Some(token) => token.index,
            None => return String::new(),
        };
        let end = match tokens.last() {
            Some(token) => token.index + token.len,
            None => return String::new(),
        };
        if start >= end {
            return String::new();
        }
        if end > self.text.len() {
            return String::new();
        }
        self.text[start..end].to_string()
    }

    pub fn stringify(&self, token: &Token) -> String {
        self.text[token.index..token.index + token.len].to_string()
    }
}
